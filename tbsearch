#! /usr/bin/python

import sqlite3
import argparse as ap
import os
import urllib
import feedparser

def enter_tb(title, author, location):
    conn = sqlite3.connect('/home/angus/programming/tbsearch/mathdoc.db')
    c = conn.cursor()

    c.execute("INSERT INTO textbooks (title, author, location) VALUES (?, ?, ?)",
            (title, author, location))
    conn.commit()

    c.close()
    conn.close()


def auto_enter(title, author, location):
    filename = author.split(' ')[-1] + '_' + title.replace(',', '').replace(' ', '_') + '.pdf'
    newpath = '/home/angus/Textbooks/math/' + filename
    #print("Path: " + newpath)
    os.rename(os.path.abspath(location), newpath)
    enter_tb(title, author, newpath)
    return newpath


# This doesn't work and I'm not sure why.
def rename_author(oldname, newname):
    c.execute("UPDATE textbooks SET author = replace(author, ?, ?)",
            (oldname, newname))

    #c.execute("UPDATE textbooks SET author = replace(author, \"" + oldname + "\", \"" + newname +"\")")
    conn.commit()


def enter_from_arxiv(id):
    # Base api query url
    base_url = 'http://export.arxiv.org/api/query?';
    
    # Search parameters
    search_query = id
    start = 0                     # retreive only the first result
    max_results = 1
    
    query = 'id_list=%s&start=%i&max_results=%i' % (search_query, start, max_results)
    
    # Opensearch metadata such as totalResults, startIndex, 
    # and itemsPerPage live in the opensearch namespase.
    # Some entry metadata lives in the arXiv namespace.
    # This is a hack to expose both of these namespaces in
    # feedparser v4.1
    #feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'
    #feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'
    
    # perform a GET request using the base_url and query
    response = urllib.request.urlopen(base_url+query).read()
    
    # parse the response using feedparser
    feed = feedparser.parse(response)
    
    authorstring = []
    
    for entry in feed.entries:
        #authors = ';'.join(author.name.split(' ')[-1] for author in entry.authors)
        #print(entry.authors)
    
        title = entry.title
        #print(title)
    
        for link in entry.links:
            if link.rel == 'alternate':
                pass
            elif link.title == 'pdf':
                pdf_link = link.href + '.pdf'
                #print(pdf_link)
    
        authorstring = ';'.join(author.name for author in entry.authors)
    
    print("Adding paper:")
    print(title)
    print("with author(s):")
    print(authorstring)
    answer = input("Is this correct? [y/n]")
    if answer == 'y':
        savefile = '/home/angus/Downloads/' + id + '.pdf'
        print('Downloading to ' + savefile)
        file_name, headers = urllib.request.urlretrieve(pdf_link, savefile)
        print('Downloaded. Moving to')
        fileloc = auto_enter(title, authorstring, file_name)
        print(fileloc)




parser = ap.ArgumentParser(description="Search textbook database")

parser.add_argument(
        '-a',
        dest='author_keyword',
        type=str,
        help="Author")

parser.add_argument(
        '-t',
        dest='title_keyword',
        type=str,
        help="Title")

parser.add_argument(
        '--add-from-arxiv',
        dest='arxiv_id',
        type=str,
        help="Arxiv id")

author_keyword = None
title_keyword = None

args = parser.parse_args()

search_stem = "SELECT title, author, location FROM textbooks WHERE "

def read_from_db():
    conn = sqlite3.connect('/home/angus/programming/tbsearch/mathdoc.db')
    c = conn.cursor()

    search_string = None
    
    if args.title_keyword and args.author_keyword:
        search_string = search_stem + "author LIKE '%" + args.author_keyword + "%' AND title LIKE '%" + args.title_keyword + "%'"
    elif args.author_keyword:
        search_string = search_stem + "author LIKE '%" + args.author_keyword + "%'"
    else:
        search_string = search_stem + "title LIKE '%" + args.title_keyword + "%'"
    if search_string:
        c.execute(search_string)
    for row in c.fetchall():
        print(row[0])
        print(row[1])
        print(row[2])
        print("")

    c.close()
    conn.close()

def main():

    if args.arxiv_id:
        enter_from_arxiv(args.arxiv_id)
    else:
        read_from_db()


main()


